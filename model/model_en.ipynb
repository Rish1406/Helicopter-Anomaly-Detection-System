{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8000e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from efficientnet_pytorch) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\documents\\major projects\\helicopter engine anamoly detection\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch torchvision matplotlib tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f901c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a04002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset path\n",
    "data_path= \"healthy_spectograms\"\n",
    "# Custom Dataset for Spectrogram Images\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = sorted([f for f in os.listdir(root_dir) if f.endswith(\".png\")])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        return self.transform(image), self.files[idx]\n",
    "#Create dataset and DataLoader\n",
    "dataset=SpectrogramDataset(data_path)\n",
    "loader=DataLoader(dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccede1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder using EfficientNet as Encoder\n",
    "class EfficientNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        base_model = EfficientNet.from_pretrained('efficientnet-b0').to(self.device)\n",
    "        self.encoder = base_model.extract_features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(1280, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(self.device)\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705f3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5cb2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "data_path = \"healthy_spectograms\"\n",
    "dataset = SpectrogramDataset(data_path)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "#Confirm sample shape\n",
    "x,name=next(iter(loader))\n",
    "print(\"Batch shape:\",x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcb7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1/100]:   4%|▍         | 26/625 [00:20<07:51,  1.27it/s, loss=1.32]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m recon = model(imgs)\n\u001b[32m     21\u001b[39m loss = criterion(recon, imgs)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m optimizer.step()\n\u001b[32m     24\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Documents\\MAJOR PROJECTS\\HELICOPTER ENGINE ANAMOLY DETECTION\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0)) \n",
    "#Initialize model and optimizer\n",
    "model = EfficientNetAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    #wrap the loader with tqdm for progress bar\n",
    "    loop=tqdm(loader,desc=f\"Epoch[{epoch+1}/{epochs}]\")\n",
    "    for imgs, _ in loop:\n",
    "        imgs = imgs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(imgs)\n",
    "        loss = criterion(recon, imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    print(f\"Epoch{epoch+1}/{epochs} | Total loss: {total_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"efficientnet_autoencoder.pth\")\n",
    "print(\"Model weights saved to efficientnet_autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetAutoencoder().to(device)\n",
    "model.load_state_dict(torch.load(\"efficientnet_autoencoder.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"Model loaded and ready for inference\")\n",
    "\n",
    "# Preprocessing for Inference\n",
    "def unnormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 1, 3)\n",
    "    return tensor * std + mean\n",
    "\n",
    "def show_reconstruction(model, loader):\n",
    "    model.eval()\n",
    "    imgs, _ = next(iter(loader))\n",
    "    imgs = imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        recon = model(imgs)\n",
    "    \n",
    "    imgs = imgs.cpu().permute(0, 2, 3, 1)\n",
    "    recon = recon.cpu().permute(0, 2, 3, 1)\n",
    "\n",
    "    for i in range(4):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        axs[0].imshow(imgs[i].numpy().clip(0, 1))\n",
    "        axs[0].set_title(\"Original\")\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        axs[1].imshow(recon[i].numpy().clip(0, 1))\n",
    "        axs[1].set_title(\"Reconstructed\")\n",
    "        axs[1].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "show_reconstruction(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"path_to_image.png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "input_tensor = transform(img).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F \n",
    "train_losses=[]\n",
    "state_dict=torch.load(\"efficientnet_autoencoder_path\",map_location=device)\n",
    "missing,unexpected=model.load_state_dict(state_dict,strict=False)\n",
    "print(\"Missing key:\",missing)\n",
    "print(\"Unexpected keys:\".unexpected)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, _ in loader:\n",
    "        imgs=imgs.to(device)\n",
    "        output=model(imgs)\n",
    "        loss=loss.mean(dim=(1,2,3))\n",
    "        train_losses.extend(loss.cpu().numpy())\n",
    "train_losses=np.array(train_losses)\n",
    "mean_loss=train_losses.mean()\n",
    "std_loss=train_losses.std()\n",
    "threshold=mean_loss+1*std_loss\n",
    "print(f\"Threshold set at : {threshold:.6f}\")\n",
    "print(f\"Mean Loss set at: {mean_loss: .6f}\")\n",
    "print(f\"std set at: {std_loss: .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_tensor = model(input_tensor)\n",
    "\n",
    "original=input_tensor\n",
    "reconstructed = output_tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    output1 = model(input_tensor)\n",
    "    output2 = model(input_tensor)\n",
    "    diff = F.mse_loss(output1, output2)\n",
    "    print(f\"Difference: {diff.item()}\")\n",
    "\n",
    "mse = F.mse_loss(reconstructed, input_tensor).item()\n",
    "print(f\"Reconstruction MSE Loss: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = original.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "recon_img = reconstructed.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(original_img)\n",
    "axs[0].set_title(\"Original Input\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(recon_img)\n",
    "axs[1].set_title(\"Reconstructed Output\")\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mse > threshold:\n",
    "    print(\"Anomaly Detected!\")\n",
    "else:\n",
    "    print(\"Normal Sample\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
